{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is K-Nearest Neighbors (KNN) and how does it work in both\n",
        "classification and regression problems?\n"
      ],
      "metadata": {
        "id": "s7kEaFGKEUoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans]\n",
        "\n",
        "KNN finds nearest data points and predicts using vote (classification) or average (regression)."
      ],
      "metadata": {
        "id": "8HhAF0uQFL8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the Curse of Dimensionality and how does it affect KNN\n",
        "performance?\n"
      ],
      "metadata": {
        "id": "1P18kCfPFU87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans]\n",
        "\n",
        "The Curse of Dimensionality means:\n",
        "\n",
        "- When the number of features (dimensions) increases, data points become far apart and less useful.\n",
        "\n",
        "dimension = feature/column\n",
        "- Example: age, salary, height, weight, etc."
      ],
      "metadata": {
        "id": "Hx3lKg3lFXqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Principal Component Analysis (PCA)? How is it different from\n",
        "feature selection?\n"
      ],
      "metadata": {
        "id": "tTeeyoGEFsRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans]\n",
        "\n",
        "Principal Component Analysis (PCA) is a dimensionality reduction technique.\n",
        "\n",
        "- It reduces the number of features while keeping most of the important information.\n",
        "\n",
        "PCA creates new features called principal components.\n",
        "\n",
        "Feature Selection means:\n",
        "\n",
        "-> Choosing the best features from the original data.\n",
        "\n",
        "- It does not create new features\n",
        "\n",
        "- It only removes unnecessary ones\n",
        "\n",
        "Example:\n",
        "\n",
        "- Original features: Age, Height, Weight, Name\n",
        "\n",
        "- Remove Name\n",
        "\n",
        "- Keep Age, Height, Weight"
      ],
      "metadata": {
        "id": "S_k8PMhAFwbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are eigenvalues and eigenvectors in PCA, and why are they\n",
        "important?"
      ],
      "metadata": {
        "id": "6B-Zq_9zGRiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans]\n",
        "\n",
        "Eigenvectors show the direction of maximum data spread (variance).\n",
        "\n",
        "In PCA:\n",
        "\n",
        "- Each eigenvector = a new axis (principal component)\n",
        "\n",
        "- They show how data is oriented\n",
        "\n",
        "Simple meaning:\n",
        "- Eigenvectors decide the direction of new features.\n",
        "\n",
        "\n",
        "Eigenvalues show how important each eigenvector is.\n",
        "\n",
        "- Large eigenvalue → more information\n",
        "\n",
        "- Small eigenvalue → less information\n",
        "\n",
        "Simple meaning:\n",
        "- Eigenvalues tell how much data variance is captured.\n",
        "\n",
        "Why Are They Important in PCA?\n",
        "\n",
        "PCA works by:\n",
        "\n",
        "1. Finding eigenvectors and eigenvalues\n",
        "\n",
        "2. Sorting them by eigenvalue (largest to smallest)\n",
        "\n",
        "3. Keeping only top eigenvectors\n",
        "\n",
        "So:\n",
        "\n",
        "- Eigenvectors → new features\n",
        "\n",
        "- Eigenvalues → which features to keep"
      ],
      "metadata": {
        "id": "m3tl80HiGVyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: How do KNN and PCA complement each other when applied in a single\n",
        "pipeline?"
      ],
      "metadata": {
        "id": "J6K2Ap0iH-Md"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans]\n",
        "Basic Idea\n",
        "\n",
        "- PCA is used first, then KNN is applied.\n",
        "\n",
        "Why?\n",
        "\n",
        "- KNN works on distance\n",
        "\n",
        "- Too many features = poor distance calculation\n",
        "\n",
        "- PCA reduces features and noise\n",
        "\n",
        "Step-by-Step Pipeline (Simple)\n",
        "\n",
        "1. PCA\n",
        "\n",
        "- Reduces number of features\n",
        "Removes noise\n",
        "\n",
        "- Keeps important information\n",
        "\n",
        "2. KNN\n",
        "\n",
        "- Finds nearest neighbors\n",
        "\n",
        "- Works faster and more accurately"
      ],
      "metadata": {
        "id": "TL3AS-VRICiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Train a KNN Classifier on the Wine dataset with and without feature\n",
        "scaling. Compare model accuracy in both cases.\n",
        "\n",
        "\n",
        "Ans]"
      ],
      "metadata": {
        "id": "AVlALnKqI4me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -------- Without Feature Scaling --------\n",
        "knn_no_scaling = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = knn_no_scaling.predict(X_test)\n",
        "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# -------- With Feature Scaling --------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_scaled = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = knn_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "acc_no_scaling, acc_scaled\n"
      ],
      "metadata": {
        "id": "qn7r8kkXJIjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Train a PCA model on the Wine dataset and print the explained variance\n",
        "ratio of each principal component.\n",
        "\n",
        "Ans]"
      ],
      "metadata": {
        "id": "qxgSJZceJMwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "\n",
        "# Feature scaling (important for PCA)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "explained_variance\n"
      ],
      "metadata": {
        "id": "hVlrUScjJTeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Train a KNN Classifier on the PCA-transformed dataset (retain top 2\n",
        "components). Compare the accuracy with the original dataset.\n",
        "\n",
        "\n",
        "Ans]"
      ],
      "metadata": {
        "id": "a6WW2OQhJcyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ---------- Original Dataset (with scaling) ----------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_original = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_original.fit(X_train_scaled, y_train)\n",
        "y_pred_original = knn_original.predict(X_test_scaled)\n",
        "acc_original = accuracy_score(y_test, y_pred_original)\n",
        "\n",
        "# ---------- PCA (Top 2 Components) ----------\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = knn_pca.predict(X_test_pca)\n",
        "acc_pca = accuracy_score(y_test, y_pred_pca)\n",
        "\n",
        "acc_original, acc_pca\n"
      ],
      "metadata": {
        "id": "DdnIVif1JqS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Train a KNN Classifier with different distance metrics (euclidean,\n",
        "manhattan) on the scaled Wine dataset and compare the results.\n",
        "\n",
        "Ans]"
      ],
      "metadata": {
        "id": "rjdITOF5J2QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# -------- KNN with Euclidean distance --------\n",
        "knn_euclidean = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
        "knn_euclidean.fit(X_train_scaled, y_train)\n",
        "y_pred_euclidean = knn_euclidean.predict(X_test_scaled)\n",
        "acc_euclidean = accuracy_score(y_test, y_pred_euclidean)\n",
        "\n",
        "# -------- KNN with Manhattan distance --------\n",
        "knn_manhattan = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
        "knn_manhattan.fit(X_train_scaled, y_train)\n",
        "y_pred_manhattan = knn_manhattan.predict(X_test_scaled)\n",
        "acc_manhattan = accuracy_score(y_test, y_pred_manhattan)\n",
        "\n",
        "acc_euclidean, acc_manhattan\n"
      ],
      "metadata": {
        "id": "xoz0bidPJ7W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You are working with a high-dimensional gene expression dataset to\n",
        "classify patients with different types of cancer.\n",
        "Due to the large number of features and a small number of samples, traditional models\n",
        "overfit.\n",
        "Explain how you would:\n",
        "● Use PCA to reduce dimensionality\n",
        "● Decide how many components to keep\n",
        "● Use KNN for classification post-dimensionality reduction\n",
        "● Evaluate the model\n",
        "● Justify this pipeline to your stakeholders as a robust solution for real-world\n",
        "biomedical data\n",
        "\n",
        "Ans]"
      ],
      "metadata": {
        "id": "0cP8R8JuJF8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Create high-dimensional data\n",
        "# -------------------------------\n",
        "X, y = make_classification(\n",
        "    n_samples=100,\n",
        "    n_features=1000,   # High-dimensional (genes)\n",
        "    n_informative=50,\n",
        "    n_classes=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Original shape:\", X.shape)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Standardize the data\n",
        "# -------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Apply PCA\n",
        "# -------------------------------\n",
        "pca = PCA(n_components=0.95)  # Keep 95% variance\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(\"Reduced shape after PCA:\", X_pca.shape)\n",
        "print(\"Explained variance:\", np.sum(pca.explained_variance_ratio_))\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Train-test split\n",
        "# -------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Apply KNN\n",
        "# -------------------------------\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Prediction and Evaluation\n",
        "# -------------------------------\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Cross-validation\n",
        "# -------------------------------\n",
        "cv_scores = cross_val_score(knn, X_pca, y, cv=5)\n",
        "\n",
        "print(\"\\nCross-validation accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "id": "v6Hq0Ne7KRZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZngYH-oEesU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUxyaAWUEPvw"
      },
      "outputs": [],
      "source": []
    }
  ]
}